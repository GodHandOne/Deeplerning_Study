{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWO4rHoio8DXbj/8jL3jdG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GodHandOne/Deeplerning_Study/blob/Chapter_5/evaluate_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K折交叉验证"
      ],
      "metadata": {
        "id": "8g9WIKuwPY4F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfVwkr4F8eKP"
      },
      "outputs": [],
      "source": [
        "k = 3\n",
        "num_validation_samples = len(data) // k\n",
        "np.random.shuffle(data)\n",
        "validation_scores = []\n",
        "for fold in range(k):\n",
        "    validation_data = data[num_validation_samples * fold:  # (本行及以下1行)选择验证数据分区\n",
        "                           num_validation_samples * (fold + 1)]\n",
        "    training_data = np.concatenate(  # (本行及以下2行)使用剩余数据作为训练数据。注意，+运算符表示列表拼接，不是加法\n",
        "        data[:num_validation_samples * fold],\n",
        "        data[num_validation_samples * (fold + 1):])\n",
        "    model = get_model()  # 创建一个全新的模型实例（未训练）\n",
        "    model.fit(training_data, ...)\n",
        "    validation_score = model.evaluate(validation_data, ...)\n",
        "    validation_scores.append(validation_score)\n",
        "validation_score = np.average(validation_scores)  # 最终验证分数：K折交叉验证分数的平均值\n",
        "model = get_model()  # (本行及以下2行)在所有非测试数据上训练最终模型\n",
        "model.fit(data, ...)\n",
        "test_score = model.evaluate(test_data, ...)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 改进模型拟合的方法"
      ],
      "metadata": {
        "id": "TWEwtj74QY9p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 调节关键的梯度下降参数"
      ],
      "metadata": {
        "id": "DcPdM3C-Qc0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), _ = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(1.),  ### 学习率设置不合理，导致出现过拟合\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(train_images, train_labels,\n",
        "          epochs=10,\n",
        "          batch_size=128,\n",
        "          validation_split=0.2)"
      ],
      "metadata": {
        "id": "ezw3ZCCrQhBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "降低或提高学习率。\n",
        "降低或提高学习率。学习率过大，可能会导致权重更新大大超出正常拟合的范围，就像前面的例子一样。学习率过小，则可能导致训练过于缓慢，以至于几乎停止。增加批量大小。如果批量包含更多样本，那么梯度将包含更多信息且噪声更少（方差更小）。"
      ],
      "metadata": {
        "id": "2xcpTeQFQzNY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 特征工程"
      ],
      "metadata": {
        "id": "Zn_rdUnET8j1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "特征工程是指将数据输入模型之前，利用你自己关于数据和机器学习算法（这里指神经网络）的知识对数据进行硬编码的变换（这种变换不是模型学到的），以改善算法的效果。在多数情况下，机器学习模型无法从完全随意的数据中进行学习。呈现给模型的数据应该便于模型进行学习。"
      ],
      "metadata": {
        "id": "t1Md_Zy7UESs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 模型正则化"
      ],
      "metadata": {
        "id": "p2tcTaATVWzs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "正则化方法是一组最佳实践，可以主动降低模型完美拟合训练数据的能力，其目的是提高模型的验证性能。它之所以被称为模型的“正则化”，是因为它通常使模型变得更简单、更“规则”，曲线更平滑、更“通用”"
      ],
      "metadata": {
        "id": "pvTxUK-3VeYd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 缩减模型容量\n",
        "通过缩减模型容量减少模型中可学习参数的个数，模型需要具有足够多的参数，以防欠拟合"
      ],
      "metadata": {
        "id": "bniMa7OYVpXt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 添加权重正则化\n",
        "给定训练数据和网络架构，多组权重值（多个模型）都可以解释这些数据，简单模型比复杂模型更不容易过拟合\n",
        "简单模型：参数值分布的熵更小的模型（或参数更少的模型，比如上一节中的例子）。\n",
        "降低过拟合的常见方法：强制让模型权重只能取较小的值，从而限制模型的复杂度，使权重值的分布更加规则，即权重正则化，实现方法是想模型损失函数中添加与去较大权重值相关的成本"
      ],
      "metadata": {
        "id": "6fRKSyS0YsNV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 将神经网络的泛化能力最大化，并防止过拟合，常用的方法\n",
        "  获取更多或更好的训练数据\n",
        "  找到更好的特征\n",
        "  缩减模型容量\n",
        "  添加权重正则化（用于较小的模型）\n",
        "  添加dropout"
      ],
      "metadata": {
        "id": "gMWEj2Nni8Eu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 深度神经网络实现泛化的方式：\n",
        "  学习一个参数化模型，使得模型能够成功地在训练样本之间进行插值\n",
        "## 机器学习的根本问题：\n",
        "  优化与泛化之间的矛盾\n",
        "## 深度学习模型泛化能力的事实：\n",
        "  模型努力逼近数据的潜在流形，从而通过插值来理解新的输入\n",
        "## 准确评估模型的泛化能力：\n",
        "  留出验证、K折交叉验证、带有打乱数据的重复K折交叉验证\n",
        "## 模型过拟合后：\n",
        "  利用模型正则化来提高泛化能力，可以缩减模型容量、添加dropout或权重正则化，以及使用EarlyStopping"
      ],
      "metadata": {
        "id": "6s8zZApzjtC6"
      }
    }
  ]
}